{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ0bxv9wZM4ROS7EAiMRny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perryqen06/ai-science-training-series/blob/main/2024-Nov-12_PerryChen_ss7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Intro to AI Series: AI Accelerators**\n",
        "\n",
        "## **Homework solutions and answers:**\n",
        "\n",
        "\n",
        "**Q1: What are the key architectural features that make these systems suitable for AI workloads?**\n",
        "\n",
        "The testbedâ€™s AI accelerators are equipped with unique hardware with AI accelerators and software features to efficiently handle a variety of AI tasks.   Unlike the traditional Von Neumann architecture, spatial Dataflow architecture is employed in these AI accelerators.  Types of AI accelerators included Wafer scale engines, RPUs,  IPUs,  TSP etc. Each of these systems is managed with specific software stacks to map the AI application among the compute units.\n",
        "\n",
        "\n",
        "\n",
        "**Q2: Identify the primary differences between these AI accelerator systems in terms of their architecture and programming models.**\n",
        "\n",
        "Cerebras CS-2 is equipped with Wafer-Scale Deep Learning Accelerator, and its software platform integrates the popular machine learning framework PyTorch.\n",
        "SambaNova has unique Dataflow Accelerator, architected around the next-generation Reconfigurable Dataflow Unit (RDU) processor for optimal dataflow processing and acceleration with RDUs interconnected to enable model and data parallelism.  SambaFlow, Sambanova's software stack, extracts, optimizes, and maps the dataflow graphs to the RDUs from standard machine learning frameworks like PyTorch.\n",
        "Graphcore is unique for its Intelligent Processing Unit (IPU), a one-rack system consisting of 64 Bow-class IPUs with a custom interconnect. The Graphcore software stack includes support for TensorFlow and PyTorch using the Poplar SDK.\n",
        "\n",
        "Groq is based on a proprietary Tensor Streaming Processor (TSP) architecture, with integrated chip-to-chip connections with a dragonfly multi-chip topology. The software stack includes Pytorch.\n",
        "\n",
        "\n",
        "**Q3: Based on hands-on sessions, describe a typical workflow for refactoring an AI model to run on one of ALCF's AI testbeds (e.g., SambaNova or Cerebras). What tools or software stacks are typically used in this process?**\n",
        "\n",
        "A typical workflow would include the following steps, with specific software stacks:\n",
        "\n",
        "\n",
        "\n",
        "--- Establish a connection to AI testbed, normally one of the nodes.\n",
        "\n",
        "--- Create and activate Virtual Environment, eg with PyTorch on Cerebras.\n",
        "\n",
        "--- Clone the Cerebras modelzoo and install corresponding requirements\n",
        "\n",
        "--- Perform job submission and queuing, and run the model, modify configuration if necessary.  The Cerebras-recommended workflow for Pipeline models uses Kubernetes (K8s) as the orchestrating software to manage resources and coordinate communication between the CS system and the other components within the Cerebras Wafer-Scale Cluster. Cerebras jobs are initiated and tracked automatically within the Python framework in modelzoo.common.pytorch.run_utils. This framework interacts with the Cerebras cluster management node.\n",
        "\n",
        "--- Monitor job progress and status and check output.\n",
        "\n",
        "\n",
        "**Q4: Give an example of a project that would benefit from AI accelerators and why?**\n",
        "\n",
        "One example that may benefit from the application of AI accelerators is the study of interaction between drugs and their targets. These interactions involves a great deal of structural, protein sequential, and functional data, as well as clinical trial outcomes. Models, eg DTI-LM, are being established and trained at presents. Large Language Models will certainly facilitate identification of targets, new therapeutic modalities, automatic experiment designs, selection of trial subjects, and outcome predictions. Advanced computational strategies with multiscale modeling using AI accelerators will be helpful in this process and would accelerate the pace of discovery and significantly decrease the cost.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4M1Krz0ZLra9"
      }
    }
  ]
}